{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ZMBmB6WhA6u",
    "outputId": "7d7ed491-ef77-49f2-f0e5-5a9f2603dd16"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: lightning in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2023.6.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.23.5)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (23.2)\n",
      "Requirement already satisfied: torch<4.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.1.0+cu118)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.2.0)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.5.0)\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning) (2.1.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning) (3.12.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning) (3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning) (2.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (3.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=1.12.0->lightning) (2.1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.12.0->lightning) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# Define a regular expression pattern to tokenize the text\n",
    "# pattern = r\"\\b\\w+\\b|\\S\"  # This pattern captures words or non-space characters\n",
    "\n",
    "# Use the findall function to tokenize the text\n",
    "# tokens = re.findall(pattern, text)\n",
    "\n",
    "df = pd.read_csv('text_emotion.csv')\n",
    "\n",
    "\n",
    "# Download NLTK data (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "\n",
    "pattern = r'\\b\\w+\\b|[\\.,!?()\\[\\]{}&*(\"^%$#@;\")=]+|\\''\n",
    "\n",
    "# Tokenize the \"content\" column\n",
    "\n",
    "# checker.correct_strings(\n",
    "#     [\"I luk foward to receving your reply\", \"were did wendigo goe boating?\"])\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: x.lower())\n",
    "# df['content'] = df['content'].apply(lambda x: checker.correct(x))\n",
    "df['tokens'] = df['content'].apply(lambda x: nltk.regexp_tokenize(x, pattern) )\n",
    "\n",
    "\n",
    "# Display the DataFrame with tokens\n",
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 947
    },
    "id": "xjtySzaihPjP",
    "outputId": "baf44f93-0f85-4a10-ce4e-141817cd8499"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         tweet_id   sentiment         author  \\\n",
       "0      1956967341       empty     xoshayzers   \n",
       "1      1956967666     sadness      wannamama   \n",
       "2      1956967696     sadness      coolfunky   \n",
       "3      1956967789  enthusiasm    czareaquino   \n",
       "4      1956968416     neutral      xkilljoyx   \n",
       "...           ...         ...            ...   \n",
       "39995  1753918954     neutral  showMe_Heaven   \n",
       "39996  1753919001        love       drapeaux   \n",
       "39997  1753919005        love       JenniRox   \n",
       "39998  1753919043   happiness       ipdaman1   \n",
       "39999  1753919049        love    Alpharalpha   \n",
       "\n",
       "                                                 content  \\\n",
       "0      @tiffanylue i know  i was listenin to bad habi...   \n",
       "1      layin n bed with a headache  ughhhh...waitin o...   \n",
       "2                    funeral ceremony...gloomy friday...   \n",
       "3                   wants to hang out with friends soon!   \n",
       "4      @dannycastillo we want to trade with someone w...   \n",
       "...                                                  ...   \n",
       "39995                                   @johnlloydtaylor   \n",
       "39996                     happy mothers day  all my love   \n",
       "39997  happy mother's day to all the mommies out ther...   \n",
       "39998  @niariley wassup beautiful!!! follow me!!  pee...   \n",
       "39999  @mopedronin bullet train from tokyo    the gf ...   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [@, tiffanylue, i, know, i, was, listenin, to,...  \n",
       "1      [layin, n, bed, with, a, headache, ughhhh, ......  \n",
       "2          [funeral, ceremony, ..., gloomy, friday, ...]  \n",
       "3         [wants, to, hang, out, with, friends, soon, !]  \n",
       "4      [@, dannycastillo, we, want, to, trade, with, ...  \n",
       "...                                                  ...  \n",
       "39995                               [@, johnlloydtaylor]  \n",
       "39996               [happy, mothers, day, all, my, love]  \n",
       "39997  [happy, mother, ', s, day, to, all, the, mommi...  \n",
       "39998  [@, niariley, wassup, beautiful, !!!, follow, ...  \n",
       "39999  [@, mopedronin, bullet, train, from, tokyo, th...  \n",
       "\n",
       "[40000 rows x 5 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-ebc4dad3-d9c4-47e4-8980-5e4f91af4cd3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>[@, tiffanylue, i, know, i, was, listenin, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>[layin, n, bed, with, a, headache, ughhhh, ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>funeral ceremony...gloomy friday...</td>\n",
       "      <td>[funeral, ceremony, ..., gloomy, friday, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends soon!</td>\n",
       "      <td>[wants, to, hang, out, with, friends, soon, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo we want to trade with someone w...</td>\n",
       "      <td>[@, dannycastillo, we, want, to, trade, with, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>1753918954</td>\n",
       "      <td>neutral</td>\n",
       "      <td>showMe_Heaven</td>\n",
       "      <td>@johnlloydtaylor</td>\n",
       "      <td>[@, johnlloydtaylor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1753919001</td>\n",
       "      <td>love</td>\n",
       "      <td>drapeaux</td>\n",
       "      <td>happy mothers day  all my love</td>\n",
       "      <td>[happy, mothers, day, all, my, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1753919005</td>\n",
       "      <td>love</td>\n",
       "      <td>JenniRox</td>\n",
       "      <td>happy mother's day to all the mommies out ther...</td>\n",
       "      <td>[happy, mother, ', s, day, to, all, the, mommi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1753919043</td>\n",
       "      <td>happiness</td>\n",
       "      <td>ipdaman1</td>\n",
       "      <td>@niariley wassup beautiful!!! follow me!!  pee...</td>\n",
       "      <td>[@, niariley, wassup, beautiful, !!!, follow, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>1753919049</td>\n",
       "      <td>love</td>\n",
       "      <td>Alpharalpha</td>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
       "      <td>[@, mopedronin, bullet, train, from, tokyo, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 5 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebc4dad3-d9c4-47e4-8980-5e4f91af4cd3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ebc4dad3-d9c4-47e4-8980-5e4f91af4cd3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ebc4dad3-d9c4-47e4-8980-5e4f91af4cd3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-2077ad1b-3a79-4cde-a339-989e4d938d35\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2077ad1b-3a79-4cde-a339-989e4d938d35')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-2077ad1b-3a79-4cde-a339-989e4d938d35 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3lfw2vqhA6x"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Initialize an empty list to store embeddings\n",
    "\n",
    "trainData = []\n",
    "\n",
    "# Tokenize and convert each word to embeddings\n",
    "for words in df['tokens']:\n",
    "  embeddings = []\n",
    "  for word in words:\n",
    "      # Tokenize the word\n",
    "      tokens = tokenizer.tokenize(word)\n",
    "      # Convert tokens to IDs\n",
    "      input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "      # Create a tensor from input IDs\n",
    "      input_ids = torch.tensor(input_ids).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "      # Get embeddings\n",
    "      with torch.no_grad():\n",
    "          outputs = model(input_ids)\n",
    "\n",
    "      # Sum the subword embeddings\n",
    "      word_embedding = torch.sum(outputs.last_hidden_state, dim=1).numpy()\n",
    "\n",
    "      embeddings.append(word_embedding.tolist()[0])\n",
    "  trainData.append(embeddings)\n",
    "\n",
    "# Now 'embeddings' contains the embeddings for each word\n",
    "# for word, embedding in zip(words, embeddings):\n",
    "#     print(f\"Word: {word}, Embedding Shape: {embedding.shape}\")\n",
    "\n",
    "# Find the maximum length of embeddings in trainData\n",
    "max_length = max(len(embedding) for embedding in trainData)\n",
    "\n",
    "padVec = [ 0 for i in range(768)]\n",
    "\n",
    "for i in range(len(trainData)):\n",
    "  while len(trainData[i]) < max_length:\n",
    "    trainData[i].append(padVec)\n",
    "\n",
    "trainData = [data for data in trainData]\n",
    "\n",
    "file_name = \"data.json\"\n",
    "\n",
    "# Open the file in write mode and store the data\n",
    "with open(file_name, \"w\") as json_file:\n",
    "    json.dump(trainData, json_file)\n",
    "\n",
    "print(f\"Data has been saved to {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PFTHE8TxhA6x",
    "ExecuteTime": {
     "end_time": "2023-11-09T23:26:23.131411200Z",
     "start_time": "2023-11-09T23:26:23.128859400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Extract the 'sentiment' column as the target variable\n",
    "sentiments = df['sentiment'].values\n",
    "\n",
    "sentiments = [[label] for label in sentiments]\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the encoder on the target variable\n",
    "y = encoder.fit_transform(sentiments)\n",
    "\n",
    "# y_train is now an array of one-hot encoded vectors\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "y2I5C9xnhA6y",
    "ExecuteTime": {
     "end_time": "2023-11-09T23:26:23.735137600Z",
     "start_time": "2023-11-09T23:26:23.728569800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 2, 3, 4, 5]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as L\n",
    "\n",
    "class DualCnnBiLsmtModel(L.LightningModule):\n",
    "    def __init__(self, embedding_dim, hidden_dim, tagset_size,senLen,lr):\n",
    "        super(DualCnnBiLsmtModel, self).__init__()\n",
    "        torch.manual_seed(seed=42)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.tagset_size = tagset_size\n",
    "        self.cnn = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(senLen, 1))\n",
    "        self.fc1 = nn.Linear(1, hidden_dim)  # Adjust the hidden_dim as needed\n",
    "        self.fc2 = nn.Linear(hidden_dim, self.tagset_size)\n",
    "        self.lstm = nn.LSTM(embedding_dim, 128//2, num_layers=1, bidirectional=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.dropout = nn.Dropout(p=0.35)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.learning_rate =lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_output1, _ = self.lstm(x)\n",
    "\n",
    "        cnn_output1 = F.relu(self.cnn(lstm_output1))\n",
    "\n",
    "        cnn_output1 = self.dropout(cnn_output1)\n",
    "        # output1 = F.max_pool1d(lstm_output1, lstm_output1.size(2)).squeeze(2)\n",
    "\n",
    "        cnn_output2 = F.relu(self.cnn(x))\n",
    "        # cnn_output1 = F.max_pool1d(cnn_output1, cnn_output1.size(2)).squeeze(2)\n",
    "        cnn_output2 = self.dropout(cnn_output2)\n",
    "        lstm_output2, _ = self.lstm(cnn_output2)\n",
    "\n",
    "        combined_output = torch.cat((lstm_output2, cnn_output1),dim=2)\n",
    "\n",
    "        output = F.max_pool1d(combined_output, combined_output.size(2))\n",
    "\n",
    "        output = output.view(combined_output.size(0), -1)\n",
    "\n",
    "        # Apply the first dense (fully connected) layer\n",
    "        output = self.fc1(output)\n",
    "        # Apply the second dense layer\n",
    "        output = self.fc2(output)\n",
    "\n",
    "        output = F.softmax(output)\n",
    "\n",
    "\n",
    "\n",
    "        # print(output.size())\n",
    "\n",
    "        # output2 = self.relu(lstm_output)  # Apply ReLU activation\n",
    "        # output2 = self.hidden2tag(lstm_output)\n",
    "        return output\n",
    "\n",
    "    def loss(self, x, y):\n",
    "      logits = self.forward(x)\n",
    "\n",
    "      criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for softmax loss\n",
    "      loss = criterion(logits, y)\n",
    "\n",
    "      return loss\n",
    "\n",
    "    # def decode(self, x):\n",
    "    #     logits = self.forward(x)\n",
    "    #     predicted_tags = self.crf.decode(logits)\n",
    "    #     return predicted_tags\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        loss = self.loss(x, y)\n",
    "        print(loss)\n",
    "        return loss\n",
    "    #0.0031622776601683794\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr= self.learning_rate)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8bKXWtDhA6y"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pytorch_lightning.callbacks import LearningRateFinder\n",
    "import lightning as L\n",
    "\n",
    "# Define the dimensions and size of your dataset\n",
    "embedding_dim = 768  # Change this to match your word embedding dimension\n",
    "hidden_dim = 128  # Change this to match your model architecture\n",
    "tagset_size = len(y[0].tolist())  # The number of classes: happy, sad, anger\n",
    "batch_size = 32\n",
    "\n",
    "trainData= torch.tensor(trainData)\n",
    "y = torch.tensor(y.tolist()).to(float)\n",
    "batch_size = 32\n",
    "dataset = TensorDataset(trainData, y)\n",
    "\n",
    "model = DualCnnBiLsmtModel(embedding_dim, hidden_dim, tagset_size, len(trainData[0]),0.1)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=1000)\n",
    "tuner = L.pytorch.tuner.Tuner(trainer)\n",
    "# Run the learning rate finder\n",
    "lr_finder = tuner.lr_find(model, train_dataloaders= dataloader, min_lr=0.000000001, max_lr=1,early_stop_threshold=None)\n",
    "\n",
    "# Plot the learning rate finder results\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "suggested_lr = lr_finder.suggestion()\n",
    "print(\"Suggested Learning Rate:\", suggested_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vS2v94B4hA6y"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "# Define the dimensions and size of your dataset\n",
    "embedding_dim = 768  # Change this to match your word embedding dimension\n",
    "hidden_dim = 128  # Change this to match your model architecture\n",
    "tagset_size = len(y[0].tolist())  # The number of classes: happy, sad, anger\n",
    "batch_size = 32\n",
    "\n",
    "trainData= torch.tensor(trainData)\n",
    "y = torch.tensor(y.tolist()).to(float)\n",
    "\n",
    "# Create a PyTorch dataset\n",
    "dataset = TensorDataset(trainData, y)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "\n",
    "# Initialize a PyTorch Lightning trainer with your desired settings\n",
    "trainer = L.Trainer(max_epochs=2000)  # Adjust max_epochs as needed\n",
    "\n",
    "# Initialize KFold cross-validation\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "# model = BiLSTMCRFModel(embedding_dim, hidden_dim, tagset_size, len(trainData[0]))\n",
    "\n",
    "# Lists to store performance metrics for each fold\n",
    "fold_metrics = []\n",
    "accuracy = 0\n",
    "# Perform 10-fold cross-validation\n",
    "for fold, (train_indices, test_indices) in enumerate(kf.split(dataset)):\n",
    "    # Create data loaders for the current fold\n",
    "\n",
    "\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, drop_last=True)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler, drop_last=True)\n",
    "\n",
    "    # Create a new model for each fold\n",
    "    model = DualCnnBiLsmtModel(embedding_dim, hidden_dim, tagset_size, len(trainData[0]),suggested_lr)\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, train_loader, test_loader)\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "\n",
    "    for batch in test_loader:  # Assuming you have a DataLoader for the test set\n",
    "      x_test, y_test = batch\n",
    "\n",
    "      # Forward pass to get model predictions\n",
    "      with torch.no_grad():  # Disable gradient tracking\n",
    "          predictions = model(x_test)\n",
    "\n",
    "\n",
    "\n",
    "      # Convert predictions to class labels by selecting the class with the highest probability\n",
    "      predicted_labels = torch.argmax(predictions, dim=1)\n",
    "      true_labels = torch.argmax(y_test, dim=1)\n",
    "\n",
    "      # Compare predicted labels with true labels\n",
    "      correct_predictions += (predicted_labels == true_labels).sum().item()\n",
    "      total_predictions += len(y_test)\n",
    "\n",
    "    # accuracy = correct_predictions / total_predictions\n",
    "    print(correct_predictions)\n",
    "    print(total_predictions)\n",
    "    accuracy += correct_predictions/total_predictions\n",
    "\n",
    "print(\"Model 10-Fold accuracy = \",accuracy/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as L\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pytorch_lightning.callbacks import LearningRateFinder\n",
    "import lightning as L\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data.dataset import random_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
